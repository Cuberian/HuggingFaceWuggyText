# -*- coding: utf-8 -*-
"""PI_lab_01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PiNRfJlgHhJSmW4U7BO0lNDfhfjZK-HG

Предварительно ставим всё, что надо
"""

!pip install transformers
!pip install torch pytorch_pretrained_bert deeppavlov

from transformers import pipeline

fill_mask = pipeline("fill-mask", model = 'DeepPavlov/rubert-base-cased', tokenizer = 'DeepPavlov/rubert-base-cased')
classifier = pipeline("sentiment-analysis", "blanchefort/rubert-base-cased-sentiment")

def predict_next_word(text: str):
  results  = fill_mask(text)
  last_words = text.split(' ')[-10:]
  last_words.append('»')
  last_words.append('"')
  last_words.append(')')
  results = list(filter(lambda d:d['token_str'] not in last_words, results))
  if len(results) == 0:
    return text[:-8]
  answer = max(results, key=lambda x:x['score'])
  if len(answer['token_str']) == 1 and text[len(text) - 9] == answer['token_str']:
    return text[:-9]
  return answer['sequence'][:-1]

newSentence = input()
for ind in range(0, 50):
  newSentence = newSentence +  f' {fill_mask.tokenizer.mask_token}.'
  newSentence = predict_next_word(newSentence)
print(newSentence)

classifier(newSentence)

!pip install transformers;
!pip install wikipedia;

from transformers import pipeline
import wikipedia

print('С кем хотите поговорить?')
who = input();
context = wikipedia.search(who)
print()
pipe = pipeline("question-answering", model="AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru");
text = wikipedia.page(context[0]).content;
print(text)
while True:
  print('Ваш вопрос:')
  qu = input();
  if qu == 'конец':
      break;
  answer = pipe(question=qu, context= text)
  print(answer["answer"])

